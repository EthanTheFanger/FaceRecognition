{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0740dbb",
   "metadata": {},
   "source": [
    "# Model Training and Testing\n",
    "\n",
    "This notebook will be used for initial testing of the siamese network as well as the YOLOv8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a00a7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general functions\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import kaggle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# YOLOv8 dependencies\n",
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17735e",
   "metadata": {},
   "source": [
    "## YoloV8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5eddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the LWF dataset to the current path\n",
    "# kaggle.api.authenticate()\n",
    "# kaggle.api.dataset_download_files(\"quadeer15sh/lfw-facial-recognition\",'.',unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff6d20",
   "metadata": {},
   "source": [
    "YOLOv8 Format asks the directory to be in this kind of format:  \n",
    "class_id | x_center | y_center | width | height  \n",
    "with class_id being alawys 0, since there are only facec pictures in wider faeces. Width and height are both normalized. \n",
    "\n",
    "While the format of the wider faces annotations for each image is in this general format:  \n",
    "< image path>  \n",
    "< number of faces>  \n",
    "< top left corner pixel > < width, height > < other attributes that I wont need, such as blur, expression, illuiation, invalid occulation pose>\n",
    "\n",
    "The wider faces dataset was originally used for a contest, so we're going to discard any portion of the dataset that doesn't have annotations, which is Wider_val and example_submission. Also going to discard the MATLAB format files from the split file. This leaves us with just 4 files, with the last two files being from the split file:  \n",
    "- Wider_test  \n",
    "- Wider_train  \n",
    "- wider_face_train_bbx_gt.txt  \n",
    "- wider_face_val_bbx_gt.txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d896a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing wider faces format to yolov8\n",
    "dir = \"./yolov8_datasets\"\n",
    "os.makedirs(dir,exist_ok=True)\n",
    "\n",
    "filename = \"yolov8.txt\"\n",
    "filepath = os.path.join(dir, filename)\n",
    "\n",
    "# wider faces directory\n",
    "dir_wf = \n",
    "\n",
    "\n",
    "# with open(filepath, 'w') as yolov8:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029ddac",
   "metadata": {},
   "source": [
    "## Siamese neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805e4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
